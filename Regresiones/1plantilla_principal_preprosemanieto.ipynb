{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1plantilla principal preprosemanieto",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1d4vX3SJtCho9tZ-8JK2AFgH5n36Guuxn",
      "authorship_tag": "ABX9TyO0dXkWL1g6Ba/5+jrpFuzz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IngCarlosCogua/maching_learn_ch/blob/main/Regresiones/1plantilla_principal_preprosemanieto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Importacion de dataset / no se necesita escalar datos para regresiones lineales simples **"
      ],
      "metadata": {
        "id": "sr_W3pHwDz5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odMIJypp2kfz"
      },
      "outputs": [],
      "source": [
        "#importacion de librerias\n",
        "import numpy as np #calculos matematicos cientificos\n",
        "import matplotlib.pyplot as plt #sublinreria para representacio  grafica\n",
        "import pandas as pd # libreria para carga y manipulacion de datos\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/Analitica_Programadorch/Archivoscsv/Data.csv')"
      ],
      "metadata": {
        "id": "MeBLnm72C6uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info() #informacion de filas y columnas del dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-fH_dWJFapU",
        "outputId": "698d0eae-7cda-4f0b-86c6-621409ce6a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Country    10 non-null     object \n",
            " 1   Age        9 non-null      float64\n",
            " 2   Salary     9 non-null      float64\n",
            " 3   Purchased  10 non-null     object \n",
            "dtypes: float64(2), object(2)\n",
            "memory usage: 448.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "g0RAMlNkG0IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dividiendo las variables predicotras X y la variable a predecir Y**"
      ],
      "metadata": {
        "id": "hN_aJttzIifp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La idea es dividir el datrafame en 2 partes  nuevas para no afectarlo X y Y por columnas donde una cantidad de datos predeciran los resultados de los datos de Y"
      ],
      "metadata": {
        "id": "Fd48g_dlIuUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X es la variable independiente predictora  y Y es la variable dependiente a predecir\n",
        "X = dataset.iloc[:,:-1].values #iloc sirve para localizar filas i columnas por posicion,[:,:-1] toma todas las filas y todas la columnas exepto la ultima en una array\n",
        "\n",
        "Y = dataset.iloc[:,3].values # toma todas la filas pero solo de la ultima columna\n",
        "\n"
      ],
      "metadata": {
        "id": "mvozLFDiFtcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X #mostrando el dataset"
      ],
      "metadata": {
        "id": "hfmqEPbLIXc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y #mostrando en dataset a predecir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAED5S62IPie",
        "outputId": "28e6600d-3e87-4afc-c293-b76a59f2d40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Division de dataset Para Entrenamiento y Testeo**"
      ],
      "metadata": {
        "id": "-R6EHkhC_jF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "del 100% de  los datos tomamos el 80 y 70 % para entrenan y el restante lo dejamos para evaluar su efectividad"
      ],
      "metadata": {
        "id": "V834wqYO_7rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # funcion que nos permite dividir el dataset original"
      ],
      "metadata": {
        "id": "LwMjQ7Oq_t-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividiendo las variables"
      ],
      "metadata": {
        "id": "XQfZzN5TCY2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#variables de entrenaiento y testeo   division de dataset , definicion de tama√±o del esteo, \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.2, random_state= 0 ) #80% de los datos o filas son para entrenaiento y 20 para testeo"
      ],
      "metadata": {
        "id": "pCy5wRpNBCcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train #contoene el 80% de los datos del dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMnmqSs0DAQn",
        "outputId": "3f4e6fb5-ee20-4084-82b3-f0fc4f5165de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Germany', 40.0, nan],\n",
              "       ['France', 37.0, 67000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Spain', nan, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['France', 44.0, 72000.0],\n",
              "       ['France', 35.0, 58000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test #contiene el 20%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf8XD2AVDFPl",
        "outputId": "e3d3089f-b449-497b-f485-4cc551b5e4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Germany', 30.0, 54000.0],\n",
              "       ['Germany', 50.0, 83000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Escalonamiento de valores***"
      ],
      "metadata": {
        "id": "mHAYGqkoQDFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalizacion de datos para que ambos esten en el mismo rango de valores, para evitar que unas variables dominenentre otras"
      ],
      "metadata": {
        "id": "EhsMImmIRRhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.preprocessing import StandardScaler  # metodo de escalonamiento estandart\n",
        "\n",
        "#creando variable escaladora\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "#Aplicando escalonamiento a la variable de entreno X\n",
        "X_train =  sc_X.fit_transform(X_train)\n",
        "# aplicamos el escalonamieto en test pero en base a el escalonamiento de train por eso no usamos la funcion fit_transform\n",
        "X_test = sc_X.transform(X_test)'''\n",
        "\n"
      ],
      "metadata": {
        "id": "DSIGb3mBDQjZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "00d3054b-05d6-4497-92c6-59dea989ade6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.preprocessing import StandardScaler  # metodo de escalonamiento estandart\\n\\n#creando variable escaladora\\nsc_X = StandardScaler()\\n\\n#Aplicando escalonamiento a la variable de entreno X\\nX_train =  sc_X.fit_transform(X_train)\\n# aplicamos el escalonamieto en test pero en base a el escalonamiento de train por eso no usamos la funcion fit_transform\\nX_test = sc_X.transform(X_test)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train #visualizando el escalonamieto ahora hay valores positivos y negativos, escala de valores cercanos distancia uclidea, ayuda a que la convergencia sea mejor"
      ],
      "metadata": {
        "id": "75-qbni3VJj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "No vamos a normalizar los datos del dataset Y_train & Y_test por que este algoritmo es de seleccion, cuando sea de prediccion si deberiamos normalizar todo\n",
        "\n"
      ],
      "metadata": {
        "id": "uSeeXobMWt08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FhzNg6GmVW0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}